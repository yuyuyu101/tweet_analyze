<html>
<head>
<link href="css/projects.css" rel="stylesheet" type="text/css">
<title>Trends</title>
</head>

<body>
<h2> Project 2: Twitter Trends </h2>

<blockquote style="text-align:center;">
  <div class="c1"><img src="texas.png"></div>

  <p>What do people tweet?<br>
    Draw their feelings on a map <br>
    to find the answer.</p>
</blockquote>

<h3>Introduction</h3>

<p> In this project, you will develop a geographic visualization of twitter data
across the USA. You will need to use dictionaries, lists, and data abstraction
techniques to keep track of your intermediate steps and create a modular
program. This project uses ideas from Sections 2.1-2.4 of the lecture notes.</p>

<p> The map displayed above depicts how the people in different states feel
about Texas.  This image is generated by:

<ol>
  <li> Collecting public Twitter posts (tweets) that have been tagged with
  geographic locations and filtering for those that contain the "texas" query
  word,
  <li> Assigning a sentiment (positive or negative) to each tweet, based on all
  of the words it contains,
  <li> Aggregating tweets by the state with the closest geographic center, and finally
  <li> Coloring each state according to the aggregate sentiment of its tweets.
  Red means positive sentiment; blue means negative.
</ol>

<p> The details of how to conduct each of these steps is contained within the
project description.  By the end of this project, you will be able to map the
sentiment of any word or phrase. There are two alternative zip archives related
to this project: 

<ul>
  <li> The <a href="trends.zip">full project</a>, which contains all the starter
  code and all data (<b>warning: 81 MB</b>).

  <li> A <a href="trends_small.zip">small version</a> that contains all the
  starter code, but only a small subset of the data.  You can complete the
  project in its entirety using this archive, and you have the option to add
  more data at the end.
</ul>

<p>The project uses several files, but all of your changes will be made to the
first one.</p>

<table cellpadding="10" cellspacing="2">
  <tr>
    <td>
      <p><code><a href="trends.py.html">trends.py</a></code></p>
    </td>

    <td>
      <p>A starter implementation of the main project file.</p>
    </td>
  </tr>

  <tr>
    <td>
      <p><code><a href="geo.py.html">geo.py</a></code></p>
    </td>

    <td>
      <p>Geographic positions, 2-D projection equations, and geographic distance functions.</p>
    </td>
  </tr>

  <tr>
    <td>
      <p><code><a href="maps.py.html">maps.py</a></code></p>
    </td>

    <td>
      <p>Functions for drawing maps.</p>
    </td>
  </tr>


  <tr>
    <td>
      <p><code><a href="data.py.html">data.py</a></code></p>
    </td>

    <td>
      <p>Functions for loading Twitter data from files.</p>
    </td>
  </tr>

  <tr>
    <td>
      <p><code><a href="graphics.py.html">graphics.py</a></code></p>
    </td>

    <td>
      <p>A simple Python graphics library.</p>
    </td>
  </tr>

  <tr>
    <td>
      <p><code><a href="ucb.py.html">ucb.py</a></code></p>
    </td>

    <td>
      <p>Utility functions for 61A.</p>
    </td>
  </tr>
</table>

<h3>Logistics</h3>

<p>This is a one-week project. You'll work in a team of two people, and you can
complete all problems together with your partner.</p>

<p>Start early! Feel free to ask for help early and often. The course staff is
here to assist you, but we can't help everyone an hour before the deadline. <a
  href="http://www.piazza.com">Piazza</a> awaits. You are not alone! </p> 

<p>In the end, you and your partner will submit one project. There are 15 possible
points. You only need to submit the file <code><a href="trends.py.html">trends.py</a></code>. You do not need
to modify any other files for this project. To submit the project, change to the
directory where the <code><a href="trends.py.html">trends.py</a></code> file is located and run <code>submit
  proj2</code>. </p> 


<h3>Phase 1: The Feelings in Tweets</h3>

<p>In this phase, you will create an abstract data type for tweets, split the
text of a tweet into words, and calculate the amount of positive or negative
feeling in a tweet.</p>

<h4>Tweets</h4>

<p>We've gotten you started on an abstract data type for tweets. Right now, we
only have the constructor, <code>make_tweet</code>, defined at the top of
<code><a href="trends.py.html">trends.py</a></code>. <code>make_tweet</code> returns a python dictionary with
the following entries:</p>

<pre>
  {'text':      &lt;a string, the text of the tweet, all in lowercase&gt;,
   'time':      &lt;a datetime object, when the tweet was posted&gt;,
   'latitude':  &lt;a floating-point number, the latitude of the tweet's location&gt;,
   'longitude': &lt;a floating-point number, the longitude of the tweet's location&gt;}
</pre> 

<h4>Problems</h4>

<p><b>Problem 1</b> (1 pt). Implement the <code>tweet_words</code> selector.
Before we can analyze the feelings in tweets, we need to access its words. We
have given you a helper function <code>extract_words</code> that breaks a string
up using spaces and returns a list of strings.</p>  
 
<p><code>tweet_words</code> is a selector function for the <code>tweet</code>
abstract data type that returns a list of words contained within the text of
the tweet.  Call the <code>extract_words</code> function to extract words from a
string. You will complete the implementation of <code>extract_words</code>
shortly.</p>

<p><b>Problem 2</b> (1 pt). Implement <code>tweet_location</code>, which is a
selector function for the <code>tweet</code> abstract data type that returns a
<code>position</code>. Positions are another abstract data type, defined at the
top of <code><a href="geo.py.html">geo.py</a></code>.  Make sure that you understand how to manipulate
positions; they play an important role in this project.

<p><b>Problem 3</b> (2 pt). Implement a better <code>extract_words</code>
function, which takes a string and returns a list of words contained in the
string.  Assume that a word is any consecutive substring of <code>text</code>
that consists only of letters.  The string <code>ascii_letters</code> in the
<code>string</code> module contains all letters in the ASCII character set.

<p>When you complete this problem, the doctest for <code>extract_words</code>
should pass.  You can also call the <code>print_sentiment</code> function, which
is currently set as the <code>@main</code> function, to print the sentiment
values of all words in a line of text.

<pre>
python3 trends.py "computer science is my favorite!"
</pre>

<p><b>Problem 4</b> (2 pt). Implement <code>analyze_tweet_sentiment</code>,
which takes a tweet (of the abstract data type) and returns a single number
averaging the weights of sentiment-carrying words in the tweet, or
<code>None</code> if none of the words in the tweet carry a sentiment weight.

<p>Read the docstrings for <code>get_word_sentiment</code> and
<code>analyze_tweet_sentiment</code> to understand how the two functions
interact.


<h3>Phase 2: The Geometry of Maps</h3> 

<h4>Positions</h4>

<p>We will use the position abstract data type to represent
geographic latitude-longitude positions on the Earth. The data abstraction,
defined at the top of <code><a href="geo.py.html">geo.py</a></code>, has the constructor
<code>make_position</code> and the selectors <code>latitude</code> and
<code>longitude</code>.  

<p>In this phase, you will write two functions that together determine the
centers of U.S. states. The shape of a state is represented as a list of
polygons.  Some states (e.g. Hawaii) consist of multiple polygons, but most
states (e.g.  Colorado) consist of only one polygon (still represented as a
length-one list).</p>

<h4>Problems</h4>

<p><b>Problem 5</b> (2 pt). Implement <code>find_centroid</code>, which takes a
polygon and returns three values: the coordinates of its centroid and its area.
The input polygon is represented as a list of <code>position</code> abstract
data types, which are the consecutive vertices of its perimeter.  The first
vertex is always identical to the last.  

<p>The centroid of a two-dimensional shape is its center of balance, defined as
the intersection of all straight lines that evenly divide the shape into
equal-area halves.  <code>find_centroid</code> returns the centroid and area of
an individual polygon.

<p>The formula for computing the <a
  href="http://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon">centroid of a
  polygon</a> appears on Wikipedia. The formula relies on vertices being
consecutive (either clockwise or counterclockwise, both give the same answer),
a property that you may assume always holds for the input.

<p>When you complete this problem, the doctest for <code>find_centroid</code>
should pass.

<p><b>Problem 6</b> (2 pt). Implement <code>find_center</code>, which takes a
shape (a list of polygons) and returns a position, its centroid.

<p>A shape is a list of polygons.  Its centroid can be computed by <a
  href="http://en.wikipedia.org/wiki/Centroid#By_geometric_decomposition">geometric
  decomposition</a>.  That is, the centroid of a shape is the weighted average of the
centroids of its component polygons, weighted by their area.  

<p>When you complete this problem, the doctest for <code>find_center</code>
should pass.

<p>Once you are finished, remove the <code>@main</code> decorator from
<code>print_sentiment</code> and add a <code>@main</code> decorator to
<code>draw_centered_map</code>. You should now be able to draw maps with labeled
states.  The labels are placed at the positions that you return from
<code>find_center</code>.  For instance, to draw the 20 states closest to
California (including California):

<pre>
python3 trends.py CA 20
</pre>


<h3>Phase 3: The Mood of the Nation</h3> 

<h4>States</h4>

<p>The name <code>us_states</code> is bound to a dictionary containing the
shape of each U.S. state, keyed by its two-letter postal code. You can use
the keys of this dictionary to iterate over all the U.S. states.

<p>In this phase, you will write functions to determine the state that a tweet
is coming from, group tweets by state, and calculate the average positive or
negative feeling in all the tweets associated with a state.</p>

<h4>Problems</h4>

<p><b>Problem 7</b> (1 pt). Implement <code>find_closest_state</code>, which
returns the two-letter postal code of the state that is closest to the location
of a tweet. Use the <code>geo_distance</code> function (provided in
<code><a href="geo.py.html">geo.py</a></code>) to calculate the shortest distance in miles between two
positions.  

<p>When you complete this problem, the doctests for
<code>find_closest_state</code> should pass.

<p><b>Problem 8</b> (2 pt). Implement <code>group_tweets_by_state</code>, which
takes a list of tweets and returns a dictionary.  The keys of the returned
dictionary are state names (two-letter postal codes), and the values are lists
of tweets that appear closer to that state's center than any other.
 
<p>When you complete this problem, the doctests for
<code>group_tweets_by_state</code> should pass.

<p><b>Problem 9</b> (2 pt). Implement <code>calculate_average_sentiments</code>.
This function takes the dictionary returned by <code>group_tweets_by_state</code> and 
also returns a dictionary.  The keys of the returned dictionary are the state names
(two-letter postal codes), and the values are average sentiment values for all the
tweets in that state.  

<p>If a state has no tweets with sentiment values, leave it out of the
dictionary entirely.  Do not include a states with no tweets, or with tweets
that have no sentiment, with a zero sentiment value.  Zero represents neutral
sentiment, not unknown sentiment.  States with unknown sentiment will appear
gray, while states with neutral sentiment will appear white.

<p>Once you are finished, remove the <code>@main</code> decorator from
<code>draw_centered_map</code> and add a <code>@main</code> decorator to
<code>draw_map_for_term</code>. You should now be able to draw maps that are
colored by sentiment corresponding to tweets that contain a given term. 

<pre>
python3 trends.py sandwich
python3 trends.py obama
python3 trends.py texas
python3 trends.py "my life"
</pre>

If you downloaded the small version of the project, you will only be able to map
these four terms.  If you would like to map any term, you will need to download
this <a href="data/all_tweets.txt">Twitter data file</a> and place it in the
<code>data</code> directory of your project.

<p><i>Congratulations!</i> One more 61A project completed.


<h3>Extensions</h3> 

<p>These extensions are optional and ungraded.  In this class, you are welcome
to program just for fun.  If you build something interesting, come to office
hours and give us a demo.

<ul>
  <li>Punctuation can be an indicator of sentiment as well.  Add an emoticon
  (smiley) detector that attributes positive sentiment to happy faces
  <code>:-)</code> and negative sentiment to sad ones.  

  <li>In the standard implementation, some tweets are associated with different
  states than the ones in which they occurred.  For example, all tweets from
  Manhattan are assigned to New Jersey.  New Yorkers would be appalled! Replace
  <code>find_closest_state</code> with a function that finds the state that
  actually contains a tweet position.

  <li>Different areas of the country may change their sentiment and level of
  Twitter activity at different times.  Can you find a time when the East Coast
  has more positive vibes than the West Coast?  Each <code>tweet</code> has a
  <a
    href="http://docs.python.org/py3k/library/datetime.html"><code>datetime</code></a>
  object that should prove useful in this extensions.

  <li>The <code><a href="graphics.py.html">graphics.py</a></code> package supports animation.  Use the
  <code>slide_shape</code> method to have states and dots slide into place.

  <li><a href="http://norvig.com/spell-correct.html">Correct the spelling</a> of
  tweets before you compute their sentiment.
</ul>

<p><b>Acknowledgements:</b> Aditi Muralidharan developed this project with John
DeNero.

</body>
</html>